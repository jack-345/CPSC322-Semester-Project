{
 "cells": [
  {
   "cell_type": "code",
   "id": "8b9abaefc4eec3c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T06:23:37.870212Z",
     "start_time": "2025-12-10T06:23:37.865821Z"
    }
   },
   "source": [
    "import importlib\n",
    "import mysklearn\n",
    "importlib.reload(mysklearn)\n",
    "\n",
    "import mysklearn.mypytable\n",
    "importlib.reload(mysklearn.mypytable)\n",
    "from mysklearn.mypytable import MyPyTable\n",
    "\n",
    "import mysklearn.myclassifiers\n",
    "importlib.reload(mysklearn.myclassifiers)\n",
    "from mysklearn.myclassifiers import MyNaiveBayesClassifier\n",
    "from mysklearn.myclassifiers import MyDecisionTreeClassifier\n",
    "from mysklearn.myclassifiers import MyRandomForestClassifier\n",
    "\n",
    "import mysklearn.myevaluation\n",
    "importlib.reload(mysklearn.myevaluation)\n",
    "import mysklearn.myevaluation as myevaluation"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "198bedb419537b78",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "For this project, we used a fully synthetic dataset from Kaggle. It contains mostly continuous data. It has 15 total attributes and 10,000 instances. We tried to classify if a crop yield was Low, Medium, or High as labels because there was no existing attribute appropriate for prediction.\n",
    "\n",
    "(findings here)\n",
    "(best performing classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875f34c98f561136",
   "metadata": {},
   "source": [
    "# Data Analysis\n",
    "\n",
    "Our dataset is mostly continuous with 10,000 instances and 15 attributes. The \"Year\" attribute is an integer representing the year of recorded instance values. The attributes Country,Region,Crop_Type, and Adaptation_Strategy are all categorical strings. The attributes Average_Temperature_C, Total_Precipitation_mm, CO2_Emissions_MT, Crop_Yield_MT_per_HA, Extreme_Weather_Events, Irrigation_Access_%, Pesticide_Use_KG_per_HA, Fertilizer_Use_KG_per_HA, Soil_Health_Index, and Economic_Impact_Million_USD are all float values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47bc4e8688af581",
   "metadata": {},
   "source": [
    "## Relevant Summary Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a40753dbc25690",
   "metadata": {},
   "source": [
    "## Data Visualizations\n",
    "\n",
    "(code cell below for function calls to display graphs?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70ba0ccb8082e95",
   "metadata": {},
   "source": [
    "# Classification Results"
   ]
  },
  {
   "cell_type": "code",
   "id": "781e7e40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T06:23:39.926030Z",
     "start_time": "2025-12-10T06:23:39.923829Z"
    }
   },
   "source": [
    "import csv\n",
    "from mysklearn.myclassifiers import MyRandomForestClassifier, MyKNeighborsClassifier\n",
    "from mysklearn.myevaluation import train_test_split, confusion_matrix, accuracy_score\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "48922679",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T06:23:41.810029Z",
     "start_time": "2025-12-10T06:23:41.805166Z"
    }
   },
   "source": [
    "def load_data(filename):\n",
    "    table = []\n",
    "    with open(filename, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        header = next(reader)\n",
    "        for row in reader:\n",
    "            table.append(row)\n",
    "    return header, table\n",
    "\n",
    "def prepare_data(header, table):\n",
    "    numeric_features = ['Average_Temperature_C', 'Total_Precipitation_mm', \n",
    "                       'CO2_Emissions_MT', 'Extreme_Weather_Events',\n",
    "                       'Irrigation_Access_%', 'Pesticide_Use_KG_per_HA', \n",
    "                       'Fertilizer_Use_KG_per_HA', 'Soil_Health_Index']\n",
    "    \n",
    "    feature_indices = [header.index(feat) for feat in numeric_features]\n",
    "    yield_index = header.index('Crop_Yield_MT_per_HA')\n",
    "    \n",
    "    X = []\n",
    "    y_continuous = []\n",
    "    for row in table:\n",
    "        try:\n",
    "            features = [float(row[i]) for i in feature_indices]\n",
    "            yield_val = float(row[yield_index])\n",
    "            X.append(features)\n",
    "            y_continuous.append(yield_val)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    sorted_yields = sorted(y_continuous)\n",
    "    p33_index = int(len(sorted_yields) * 0.33)\n",
    "    p67_index = int(len(sorted_yields) * 0.67)\n",
    "    p33 = sorted_yields[p33_index]\n",
    "    p67 = sorted_yields[p67_index]\n",
    "    \n",
    "    y = []\n",
    "    for yield_val in y_continuous:\n",
    "        if yield_val < p33:\n",
    "            y.append('Low')\n",
    "        elif yield_val < p67:\n",
    "            y.append('Medium')\n",
    "        else:\n",
    "            y.append('High')\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def print_confusion_matrix(matrix, labels):\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"{'':12}\", end=\"\")\n",
    "    for label in labels:\n",
    "        print(f\"{label:>10}\", end=\"\")\n",
    "    print()\n",
    "    print(\"-\" * 50)\n",
    "    for i, label in enumerate(labels):\n",
    "        print(f\"{label:12}\", end=\"\")\n",
    "        for j in range(len(labels)):\n",
    "            print(f\"{matrix[i][j]:>10}\", end=\"\")\n",
    "        print()\n",
    "\n",
    "def discretize_features(X):\n",
    "    \"\"\"Convert continuous features to categorical bins for Naive Bayes.\"\"\"\n",
    "    X_discretized = []\n",
    "    \n",
    "    # First, find min/max for each feature to create bins\n",
    "    n_features = len(X[0])\n",
    "    feature_mins = [min(instance[i] for instance in X) for i in range(n_features)]\n",
    "    feature_maxs = [max(instance[i] for instance in X) for i in range(n_features)]\n",
    "    \n",
    "    for instance in X:\n",
    "        discretized_instance = []\n",
    "        for i, value in enumerate(instance):\n",
    "            # Create 3 equal-width bins: Low, Medium, High\n",
    "            range_size = (feature_maxs[i] - feature_mins[i]) / 3\n",
    "            if value < feature_mins[i] + range_size:\n",
    "                discretized_instance.append('Low')\n",
    "            elif value < feature_mins[i] + 2 * range_size:\n",
    "                discretized_instance.append('Medium')\n",
    "            else:\n",
    "                discretized_instance.append('High')\n",
    "        X_discretized.append(discretized_instance)\n",
    "    \n",
    "    return X_discretized"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "fac577a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T06:23:45.000012Z",
     "start_time": "2025-12-10T06:23:44.943621Z"
    }
   },
   "source": [
    "filename = 'climate_change_impact_on_agriculture_2024.csv'\n",
    "header, table = load_data(filename)\n",
    "X, y = prepare_data(header, table)\n",
    "\n",
    "print(f\"Dataset: {len(X)} instances, {len(X[0])} features\")\n",
    "print(f\"Classes: Low, Medium, High\")\n",
    "\n",
    "# Split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "print(f\"Training: {len(X_train)} instances\")\n",
    "print(f\"Test: {len(X_test)} instances\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: 10000 instances, 8 features\n",
      "Classes: Low, Medium, High\n",
      "Training: 6700 instances\n",
      "Test: 3300 instances\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "1d0fb950",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T06:23:55.844564Z",
     "start_time": "2025-12-10T06:23:46.910395Z"
    }
   },
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"RANDOM FOREST CLASSIFIER\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "rf = MyRandomForestClassifier(n_trees=10, max_depth=5)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_pred = rf.predict(X_test)\n",
    "rf_acc = accuracy_score(y_test, rf_pred)\n",
    "\n",
    "print(f\"Accuracy: {rf_acc:.4f} ({rf_acc*100:.2f}%)\")\n",
    "\n",
    "labels = ['Low', 'Medium', 'High']\n",
    "rf_matrix = confusion_matrix(y_test, rf_pred, labels)\n",
    "print_confusion_matrix(rf_matrix, labels)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RANDOM FOREST CLASSIFIER\n",
      "============================================================\n",
      "Accuracy: 0.3282 (32.82%)\n",
      "\n",
      "Confusion Matrix:\n",
      "==================================================\n",
      "                   Low    Medium      High\n",
      "--------------------------------------------------\n",
      "Low                662       207       196\n",
      "Medium             698       235       180\n",
      "High               709       227       186\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "bc5c9aa7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T06:24:19.444655Z",
     "start_time": "2025-12-10T06:23:59.553950Z"
    }
   },
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"K-NEAREST NEIGHBORS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "knn = MyKNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "knn_pred = knn.predict(X_test)\n",
    "knn_acc = accuracy_score(y_test, knn_pred)\n",
    "\n",
    "print(f\"Accuracy: {knn_acc:.4f} ({knn_acc*100:.2f}%)\")\n",
    "\n",
    "knn_matrix = confusion_matrix(y_test, knn_pred, labels)\n",
    "print_confusion_matrix(knn_matrix, labels)\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"NAIVE BAYES CLASSIFIER\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Discretizing continuous features into Low/Medium/High bins...\")\n",
    "\n",
    "# Discretize features for Naive Bayes\n",
    "X_train_disc = discretize_features(X_train)\n",
    "X_test_disc = discretize_features(X_test)\n",
    "\n",
    "# Train Naive Bayes\n",
    "nb = MyNaiveBayesClassifier()\n",
    "nb.fit(X_train_disc, y_train)\n",
    "nb_pred = nb.predict(X_test_disc)\n",
    "nb_acc = accuracy_score(y_test, nb_pred)\n",
    "\n",
    "print(f\"\\n‚úì Naive Bayes Accuracy: {nb_acc:.4f} ({nb_acc*100:.2f}%)\")\n",
    "\n",
    "nb_matrix = confusion_matrix(y_test, nb_pred, labels)\n",
    "print_confusion_matrix(nb_matrix, labels)\n",
    "\n",
    "# Calculate per-class accuracy\n",
    "print(\"\\nPer-Class Recognition Rates:\")\n",
    "for i, label in enumerate(labels):\n",
    "    total = sum(nb_matrix[i])\n",
    "    correct = nb_matrix[i][i]\n",
    "    rate = (correct / total * 100) if total > 0 else 0\n",
    "    print(f\"  {label}: {correct}/{total} = {rate:.1f}%\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "K-NEAREST NEIGHBORS\n",
      "============================================================\n",
      "Accuracy: 0.3748 (37.48%)\n",
      "\n",
      "Confusion Matrix:\n",
      "==================================================\n",
      "                   Low    Medium      High\n",
      "--------------------------------------------------\n",
      "Low                349       377       339\n",
      "Medium             331       411       371\n",
      "High               277       368       477\n",
      "\n",
      "============================================================\n",
      "NAIVE BAYES CLASSIFIER\n",
      "============================================================\n",
      "Discretizing continuous features into Low/Medium/High bins...\n",
      "\n",
      "‚úì Naive Bayes Accuracy: 0.4727 (47.27%)\n",
      "\n",
      "Confusion Matrix:\n",
      "==================================================\n",
      "                   Low    Medium      High\n",
      "--------------------------------------------------\n",
      "Low                550        37       478\n",
      "Medium             442        33       638\n",
      "High               113        32       977\n",
      "\n",
      "Per-Class Recognition Rates:\n",
      "  Low: 550/1065 = 51.6%\n",
      "  Medium: 33/1113 = 3.0%\n",
      "  High: 977/1122 = 87.1%\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "0403b688",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T06:24:28.608728Z",
     "start_time": "2025-12-10T06:24:28.603794Z"
    }
   },
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"FINAL COMPARISON\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nOverall Accuracy:\")\n",
    "print(f\"  Random Forest:  {rf_acc:.4f} ({rf_acc*100:.2f}%)\")\n",
    "print(f\"  k-NN (k=5):     {knn_acc:.4f} ({knn_acc*100:.2f}%)\")\n",
    "print(f\"  Naive Bayes:    {nb_acc:.4f} ({nb_acc*100:.2f}%)\")\n",
    "\n",
    "# Find winner\n",
    "accuracies = [('Random Forest', rf_acc), ('k-NN', knn_acc), ('Naive Bayes', nb_acc)]\n",
    "accuracies_sorted = sorted(accuracies, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(f\"\\nüèÜ Rankings:\")\n",
    "for i, (name, acc) in enumerate(accuracies_sorted, 1):\n",
    "    print(f\"  {i}. {name}: {acc:.4f} ({acc*100:.2f}%)\")\n",
    "\n",
    "winner = accuracies_sorted[0]\n",
    "print(f\"\\nüèÜ Winner: {winner[0]} with {winner[1]*100:.2f}% accuracy!\")\n",
    "\n",
    "# Show differences\n",
    "print(f\"\\nPerformance Gaps:\")\n",
    "print(f\"  1st vs 2nd: {(accuracies_sorted[0][1] - accuracies_sorted[1][1])*100:.2f} percentage points\")\n",
    "print(f\"  1st vs 3rd: {(accuracies_sorted[0][1] - accuracies_sorted[2][1])*100:.2f} percentage points\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ANALYSIS COMPLETE\")\n",
    "print(\"=\" * 70)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "FINAL COMPARISON\n",
      "======================================================================\n",
      "\n",
      "Overall Accuracy:\n",
      "  Random Forest:  0.3282 (32.82%)\n",
      "  k-NN (k=5):     0.3748 (37.48%)\n",
      "  Naive Bayes:    0.4727 (47.27%)\n",
      "\n",
      "üèÜ Rankings:\n",
      "  1. Naive Bayes: 0.4727 (47.27%)\n",
      "  2. k-NN: 0.3748 (37.48%)\n",
      "  3. Random Forest: 0.3282 (32.82%)\n",
      "\n",
      "üèÜ Winner: Naive Bayes with 47.27% accuracy!\n",
      "\n",
      "Performance Gaps:\n",
      "  1st vs 2nd: 9.79 percentage points\n",
      "  1st vs 3rd: 14.45 percentage points\n",
      "\n",
      "======================================================================\n",
      "ANALYSIS COMPLETE\n",
      "======================================================================\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "id": "95091b7bf40d8e36",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1d0a8831b7354a",
   "metadata": {},
   "source": [
    "# Acknowledgements\n",
    "\n",
    "Claude AI was used for assistance in this project for helping understanding and developing Random Forest and its unit tests, and correcting bugs in our EDA code. Our Naive Bayes and kNN classifier code was taken from previous PAs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
